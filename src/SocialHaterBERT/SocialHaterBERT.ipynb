{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv8fiPZsFa5f"
      },
      "source": [
        "# Construcci√≥n del modelo final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26RtC6xJFa5g"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install multimodal-transformers\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "from dataclasses import dataclass, field\n",
        "from multimodal_transformers.data import load_data_from_folder\n",
        "from multimodal_transformers.model import TabularConfig\n",
        "from multimodal_transformers.model import AutoModelWithTabular\n",
        "from transformers.training_args import TrainingArguments\n",
        "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, Trainer, EvalPrediction, set_seed)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "os.environ['COMET_MODE'] = 'DISABLED'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpTGMUmAFa5h"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('df_final_3391.csv')\n",
        "train_df, val_df, test_df = np.split(data_df.sample(frac=1), [int(.8*len(data_df)), int(.9 * len(data_df))]) #8:1:1, cambiar\n",
        "print('Num examples train-val-test')\n",
        "print(len(train_df), len(val_df), len(test_df))\n",
        "train_df.to_csv('train.csv')\n",
        "val_df.to_csv('val.csv')\n",
        "test_df.to_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr3yWObWFa5i"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "  \"\"\"\n",
        "  Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "  \"\"\"\n",
        "\n",
        "  model_name_or_path: str = field(\n",
        "      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "  )\n",
        "  config_name: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "  )\n",
        "  tokenizer_name: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "  )\n",
        "  cache_dir: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
        "  )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MultimodalDataTrainingArguments:\n",
        "  \"\"\"\n",
        "  Arguments pertaining to how we combine tabular features\n",
        "  Using `HfArgumentParser` we can turn this class\n",
        "  into argparse arguments to be able to specify them on\n",
        "  the command line.\n",
        "  \"\"\"\n",
        "\n",
        "  data_path: str = field(metadata={\n",
        "                            'help': 'the path to the csv file containing the dataset'\n",
        "                        })\n",
        "  column_info_path: str = field(\n",
        "      default=None,\n",
        "      metadata={\n",
        "          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n",
        "  })\n",
        "\n",
        "  column_info: dict = field(\n",
        "      default=None,\n",
        "      metadata={\n",
        "          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n",
        "                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n",
        "  })\n",
        "\n",
        "  categorical_encode_type: str = field(default='ohe',\n",
        "                                        metadata={\n",
        "                                            'help': 'sklearn encoder to use for categorical data',\n",
        "                                            'choices': ['ohe', 'binary', 'label', 'none']\n",
        "                                        })\n",
        "  numerical_transformer_method: str = field(default='box_cox',\n",
        "                                            metadata={\n",
        "                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n",
        "                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n",
        "                                            })\n",
        "  task: str = field(default=\"classification\",\n",
        "                    metadata={\n",
        "                        \"help\": \"The downstream training task\",\n",
        "                        \"choices\": [\"classification\", \"regression\"]\n",
        "                    })\n",
        "\n",
        "  mlp_division: int = field(default=4,\n",
        "                            metadata={\n",
        "                                'help': 'the ratio of the number of '\n",
        "                                        'hidden dims in a current layer to the next MLP layer'\n",
        "                            })\n",
        "  combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
        "                                    metadata={\n",
        "                                        'help': 'method to combine categorical and numerical features, '\n",
        "                                                'see README for all the method'\n",
        "                                    })\n",
        "  mlp_dropout: float = field(default=0.1,\n",
        "                              metadata={\n",
        "                                'help': 'dropout ratio used for MLP layers'\n",
        "                              })\n",
        "  numerical_bn: bool = field(default=True,\n",
        "                              metadata={\n",
        "                                  'help': 'whether to use batchnorm on numerical features'\n",
        "                              })\n",
        "  use_simple_classifier: str = field(default=True,\n",
        "                                      metadata={\n",
        "                                          'help': 'whether to use single layer or MLP as final classifier'\n",
        "                                      })\n",
        "  mlp_act: str = field(default='relu',\n",
        "                        metadata={\n",
        "                            'help': 'the activation function to use for finetuning layers',\n",
        "                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n",
        "                        })\n",
        "  gating_beta: float = field(default=0.2,\n",
        "                              metadata={\n",
        "                                  'help': \"the beta hyperparameters used for gating tabular data \"\n",
        "                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n",
        "                              })\n",
        "\n",
        "  def __post_init__(self):\n",
        "      assert self.column_info != self.column_info_path\n",
        "      if self.column_info is None and self.column_info_path:\n",
        "          with open(self.column_info_path, 'r') as f:\n",
        "              self.column_info = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd8bejl6Fa5j"
      },
      "outputs": [],
      "source": [
        "text_cols = ['text']\n",
        "cat_cols = ['hater', 'vecino_hater', 'profile_changed', 'verificado', 'clase_NER', 'clase_DESCR',\n",
        "            'clase_FECHA', 'clase_IMG', 'clase_HASHTAGS', 'clase_CATEGORIAS', 'clase_MENCAT', 'clase_RTSCAT','clase_DOMS'] #  ,'clase_LOC', 'clase_LESP', 'clase_LENG', 'clase_LOTR'\n",
        "numerical_cols = ['negativos', 'positivos', 'neutros', 'n_hate', 'n_nohate', 'n_baddies',\n",
        "                  #'activity_weekly_0', 'activity_weekly_1', 'activity_weekly_2', 'activity_weekly_3', \n",
        "                  #'activity_weekly_4', 'activity_weekly_5', 'activity_weekly_6', 'activity_hourly_00', \n",
        "                  #'activity_hourly_01', 'activity_hourly_02', 'activity_hourly_03', 'activity_hourly_04', \n",
        "                  #'activity_hourly_05', 'activity_hourly_06', 'activity_hourly_07', 'activity_hourly_08', \n",
        "                  #'activity_hourly_09', 'activity_hourly_10', 'activity_hourly_11', 'activity_hourly_12', \n",
        "                  #'activity_hourly_13', 'activity_hourly_14', 'activity_hourly_15', 'activity_hourly_16', \n",
        "                  #'activity_hourly_17', 'activity_hourly_18', 'activity_hourly_19', 'activity_hourly_20', \n",
        "                  #'activity_hourly_21', 'activity_hourly_22', 'activity_hourly_23', \n",
        "                  'eigenvector', 'in_degree',\n",
        "                  'out_degree', 'degree', 'clustering', 'closeness', \n",
        "                  'negativos_score', 'positivos_score', \n",
        "                  'neutros_score', 'hate_score', 'no_hate_score', 'statuses_count', 'followers_count', 'followees_count', \n",
        "                  'listed_count', 'num_hashtags', 'rt_count', 'num_mentions', 'num_urls', 'len_status', 'times_user_quotes', \n",
        "                  'num_rts_to_tweets', 'misspelling_counter', 'leet_counter', 'betweenness', 'status_average_tweets_per_day']\n",
        "                \n",
        "\n",
        "column_info_dict = {\n",
        "    'text_cols': text_cols,\n",
        "    'num_cols': numerical_cols,\n",
        "    'cat_cols': cat_cols,\n",
        "    'label_col': 'label',\n",
        "    'label_list': [0,1]\n",
        "}\n",
        "\n",
        "\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path='dccuchile/bert-base-spanish-wwm-cased'\n",
        ")\n",
        "\n",
        "data_args = MultimodalDataTrainingArguments(\n",
        "    data_path='.',\n",
        "    combine_feat_method='gating_on_cat_and_num_feats_then_sum', #\n",
        "    column_info=column_info_dict,\n",
        "    task='classification'\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./logs/model_name\",\n",
        "    logging_dir=\"./logs/runs\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=7, #7\n",
        "    evaluate_during_training=True,\n",
        "    logging_steps=25,\n",
        "    eval_steps=250, #250\n",
        "    dataloader_drop_last=True\n",
        ")\n",
        "\n",
        "set_seed(training_args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vK-xIclFa5k"
      },
      "outputs": [],
      "source": [
        "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
        "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    tokenizer_path_or_name,\n",
        "    cache_dir=model_args.cache_dir,\n",
        ")\n",
        "#inputs = tokenizer(sentences, padding=\"max_length\", truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8e52A81ZQDY"
      },
      "outputs": [],
      "source": [
        "data_args.data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhZkwaJpFa5k"
      },
      "outputs": [],
      "source": [
        "# Get Datasets\n",
        "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
        "    data_args.data_path,\n",
        "    data_args.column_info['text_cols'],\n",
        "    tokenizer,\n",
        "    label_col=data_args.column_info['label_col'],\n",
        "    label_list=data_args.column_info['label_list'],\n",
        "    categorical_cols=data_args.column_info['cat_cols'],\n",
        "    numerical_cols=data_args.column_info['num_cols'],\n",
        "    sep_text_token_str=tokenizer.sep_token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hKu8HX9Fa5k"
      },
      "outputs": [],
      "source": [
        "num_labels = len(np.unique(train_dataset.labels))\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xjDv1FcFa5l"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "tabular_config = TabularConfig(num_labels=num_labels,\n",
        "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
        "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
        "                               **vars(data_args))\n",
        "config.tabular_config = tabular_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mokaBSlLJ_Rb"
      },
      "outputs": [],
      "source": [
        "model = AutoModelWithTabular.from_pretrained(\n",
        "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "    config=config,\n",
        "    cache_dir=model_args.cache_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAkvwjGNvw_y"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-fbysl1Fa5l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import (\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    matthews_corrcoef,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "def calc_classification_metrics(p: EvalPrediction):\n",
        "  pred_labels = np.argmax(p.predictions, axis=1)\n",
        "  pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
        "  labels = p.label_ids\n",
        "  if len(np.unique(labels)) == 2:  # binary classification\n",
        "      roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
        "      #accuracy = accuracy_score(labels, pred_scores)\n",
        "      precisions, recalls, thresholds = precision_recall_curve(labels,\n",
        "                                                                pred_scores)\n",
        "      fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
        "      fscore[np.isnan(fscore)] = 0\n",
        "      ix = np.argmax(fscore)\n",
        "      threshold = thresholds[ix].item()\n",
        "      pr_auc = auc(recalls, precisions)\n",
        "      tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
        "      result = {#'accuracy' : accuracy_score,\n",
        "                'roc_auc': roc_auc_pred_score,\n",
        "                'threshold': threshold,\n",
        "                'pr_auc': pr_auc,\n",
        "                'recall': recalls[ix].item(),\n",
        "                'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n",
        "                'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n",
        "                }\n",
        "  else:\n",
        "      acc = (pred_labels == labels).mean()\n",
        "      f1 = f1_score(y_true=labels, y_pred=pred_labels)\n",
        "      result = {\n",
        "          \"acc\": acc,\n",
        "          \"f1\": f1,\n",
        "          \"acc_and_f1\": (acc + f1) / 2,\n",
        "          \"mcc\": matthews_corrcoef(labels, pred_labels)\n",
        "      }\n",
        "  print(result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lj-1O71Fa5m"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=calc_classification_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLX85q4bnikj"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRTsmRZmdWf7"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reV-epkPFa5n"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWX5cu_jFa5n"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./logs/runs --port=6006"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SocialHaterBERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
