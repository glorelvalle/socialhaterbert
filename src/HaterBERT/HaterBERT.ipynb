{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab\n",
    "import sys\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "sys.path.insert(0,'/content/drive/My Drive/ColabNotebooks/modelobert')\n",
    "%cd drive/MyDrive/'Colab Notebooks'/modelobert\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.5.1\n",
    "!pip install neptune-client==0.4.130"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H19HVNTBzpw"
   },
   "source": [
    "# HaterBERT code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plqEMpGJCDVx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import neptune\n",
    "import datetime\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multilingual_bert import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score,recall_score, precision_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "\n",
    "from transformers.models.bert.modeling_bert import *\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "# Este entorno lo ejecuto en Google Colab\n",
    "device = torch.device(\"cuda\")\n",
    "print('Hay %d GPU(s) disponibles.' % torch.cuda.device_count())\n",
    "print('Se usarÃ¡ GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Set the gpu device\n",
    "print(\"current gpu device\", torch.cuda.current_device())\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "api_token=\"YOUR_KEY_NEPTUNE\"\n",
    "project_name='YOUR_DIR_NEPTUNE'\n",
    "\n",
    "batch_size = 8\n",
    "MAX_LEN = 512\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Function to tokenize given sentences\n",
    "def custom_tokenize(sentences,tokenizer,max_length=512):\n",
    "    input_ids = []\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        try:\n",
    "\n",
    "            encoded_sent = tokenizer.encode(\n",
    "                                sent,                      # Sentence to encode.\n",
    "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                max_length = max_length,\n",
    "                                # This function also supports truncation and conversion\n",
    "                                # to pytorch tensors, but we need to do padding, so we\n",
    "                                # can't use these features :( .\n",
    "                                #max_length = 128,          # Truncate all sentences.\n",
    "                                #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                           )\n",
    "\n",
    "            # Add the encoded sentence to the list.\n",
    "\n",
    "        except ValueError:\n",
    "            encoded_sent = tokenizer.encode(\n",
    "                                ' ',                      # Sentence to encode.\n",
    "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                max_length = max_length,\n",
    "                                # This function also supports truncation and conversion\n",
    "                                # to pytorch tensors, but we need to do padding, so we\n",
    "                                # can't use these features :( .\n",
    "                                #max_length = 128,          # Truncate all sentences.\n",
    "                                #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                           )\n",
    "              ### decide what to later\n",
    "\n",
    "        input_ids.append(encoded_sent)\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "# Create mask for the given inputs.\n",
    "def custom_att_masks(input_ids):\n",
    "    attention_masks = []\n",
    "\n",
    "    # For each sentence...\n",
    "    for sent in input_ids:\n",
    "\n",
    "        # Create the attention mask.\n",
    "        #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "        #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "        # Store the attention mask for this sentence.\n",
    "        attention_masks.append(att_mask)\n",
    "    return attention_masks\n",
    "\n",
    "# Truncate and Tokenize sentences, then pad them\n",
    "def combine_features(sentences,tokenizer,max_length=512):\n",
    "    input_ids=custom_tokenize(sentences,tokenizer,max_length)\n",
    "    input_ids = pad_sequences(input_ids, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "    #print(input_ids.shape)\n",
    "    att_masks=custom_att_masks(input_ids)\n",
    "    return input_ids,att_masks\n",
    "\n",
    "# Generate pytorch data loader with the given dataset.\n",
    "def return_dataloader(input_ids,labels,att_masks,batch_size=8,is_train=False):\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    labels = torch.tensor(labels,dtype=torch.long)\n",
    "    masks = torch.tensor(np.array(att_masks))\n",
    "    data = TensorDataset(inputs, masks, labels)\n",
    "    if(is_train==False):\n",
    "        sampler = SequentialSampler(data)\n",
    "    else:\n",
    "        sampler = RandomSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "# Sample the given dataframe df to select n_sample number of points.\n",
    "def stratified_sample_df(df, col, n_samples,sampled='stratified',random_state=1):\n",
    "    if(sampled=='stratified'):\n",
    "        df_=df.groupby(col, group_keys=False).apply(lambda x: x.sample(int(np.rint(n_samples*len(x)/len(df))))).sample(frac=1,random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    elif(sampled=='equal'):\n",
    "        df_=df.groupby(col, group_keys=False).apply(lambda x: x.sample(int(n_samples/2))).sample(frac=1,random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    return df_\n",
    "\n",
    "###### data collection taking all at a time\n",
    "def data_collector(file_names,params,is_train):\n",
    "    if(params['csv_file']=='*_full.csv'):\n",
    "        index=12\n",
    "    elif(params['csv_file']=='*_translated.csv'):\n",
    "        index=23\n",
    "    sample_ratio=params['sample_ratio']\n",
    "    type_train=params['how_train']\n",
    "    sampled=params['samp_strategy']\n",
    "    take_ratio=params['take_ratio']\n",
    "    language=params['language']\n",
    "    print(\"Language {0}\".format(language))\n",
    "    print(file_names)\n",
    "    # If the data being loaded is not train, i.e. either val or test, load everything and return\n",
    "    if(is_train!=True):\n",
    "        df_test=[]\n",
    "        for file in file_names:\n",
    "            lang_temp=file.split('/')[-1][:-index]\n",
    "            if(lang_temp==language):\n",
    "                df_test.append(pd.read_csv(file))\n",
    "        df_test=pd.concat(df_test,axis=0)\n",
    "        return df_test\n",
    "    # If train data is being loaded,\n",
    "    else:\n",
    "        # Baseline setting - only target language data is loaded\n",
    "        if(type_train=='baseline'):\n",
    "            df_test=[]\n",
    "            for file in file_names:\n",
    "\n",
    "                lang_temp=file.split('/')[-1][:-index]\n",
    "                #print(lang_temp+ ' h')\n",
    "                #print(language)\n",
    "\n",
    "                if(lang_temp==language):\n",
    "                    temp=pd.read_csv(file)\n",
    "                    df_test.append(temp)\n",
    "            df_test=pd.concat(df_test,axis=0)\n",
    "        # Zero shot setting - all except target language loaded\n",
    "        if(type_train=='zero_shot'):\n",
    "            df_test=[]\n",
    "            for file in file_names:\n",
    "                lang_temp=file.split('/')[-1][:-index]\n",
    "                if(lang_temp=='English'):\n",
    "                    temp=pd.read_csv(file)\n",
    "\n",
    "                    df_test.append(temp)\n",
    "            df_test=pd.concat(df_test,axis=0)\n",
    "\n",
    "        # All_but_one - all other languages fully loaded, target language sampled\n",
    "        if(type_train=='all_but_one'):\n",
    "            df_test=[]\n",
    "            for file in file_names:\n",
    "                lang_temp=file.split('/')[-1][:-index]\n",
    "                if(lang_temp!=language):\n",
    "                    temp=pd.read_csv(file)\n",
    "                    df_test.append(temp)\n",
    "            df_test=pd.concat(df_test,axis=0)\n",
    "\n",
    "\n",
    "        if(take_ratio==True):\n",
    "            n_samples=int(len(df_test)*sample_ratio/100)\n",
    "        else:\n",
    "            #n_samples=sample_ratio\n",
    "            n_samples=int(len(df_test))\n",
    "\n",
    "        if(n_samples==0):\n",
    "            n_samples+=1\n",
    "        df_test=stratified_sample_df(df_test, 'label', n_samples,sampled,params['random_seed'])\n",
    "        return df_test\n",
    "\n",
    "# Function to set the random seeds for reproducibility\n",
    "def fix_the_random(seed_val = 42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    #pred_flat = np.argmax(preds, axis=0).flatten()\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def flat_fscore(preds, labels):\n",
    "    #pred_flat = np.argmax(preds, axis=0).flatten()\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, pred_flat, average='macro')\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Function to save models\n",
    "def save_model(model,tokenizer,params):\n",
    "    if(params['to_save']==True):\n",
    "        if(params['csv_file']=='*_full.csv'):\n",
    "            translate='translated'\n",
    "        else:\n",
    "            translate='actual'\n",
    "        # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "        if(params['how_train']!='all'):\n",
    "            output_dir = 'models_saved/'+params['path_files']+'_'+params['language']+'_'+translate+'_'+params['how_train']+'_'+str(params['sample_ratio'])\n",
    "        else:\n",
    "            output_dir = 'models_saved/'+params['path_files']+'_'+translate+'_'+params['how_train']+'_'+str(params['sample_ratio'])\n",
    "\n",
    "        if(params['save_only_bert']):\n",
    "            model=model.bert\n",
    "            output_dir=output_dir+'_only_bert/'\n",
    "        else:\n",
    "            output_dir=output_dir+'/'\n",
    "        print(output_dir)\n",
    "        # Create output directory if needed\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "        # They can then be reloaded using `from_pretrained()`\n",
    "\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(output_dir)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Function to select model based on parameters passed\n",
    "def select_model(type_of_model,path,weights=None,label_list=None):\n",
    "    if(type_of_model=='weighted'):\n",
    "        model = SC_weighted_BERT.from_pretrained(\n",
    "        path, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "        num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.\n",
    "        output_attentions = False, # Whether the model returns attentions weights.\n",
    "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        weights=weights\n",
    "    )\n",
    "    elif(type_of_model=='normal'):\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "          path, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "          num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.\n",
    "          output_attentions = False, # Whether the model returns attentions weights.\n",
    "          output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    elif(type_of_model=='multitask'):\n",
    "        model = BertForMultitask.from_pretrained(\n",
    "          path, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "          num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.\n",
    "          output_attentions = False, # Whether the model returns attentions weights.\n",
    "          output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "          label_uniques=label_list\n",
    "        )\n",
    "    elif(type_of_model=='bert_cnn'):\n",
    "        model = BERT_CNN.from_pretrained(\n",
    "          path, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "          num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.\n",
    "          output_attentions = False, # Whether the model returns attentions weights.\n",
    "          output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error in model name!!!!\")\n",
    "    return model\n",
    "\n",
    "## Class BERT+CNN from \"A BERT-based...\"\n",
    "class BERT_CNN(BertPreTrainedModel):#\n",
    "  def __init__(self, config):\n",
    "    print('init bert+cnn')\n",
    "    super().__init__(config)\n",
    "    self.num_labels = config.num_labels\n",
    "    self.bert = BertModel(config)\n",
    "    #self.conv = nn.Conv2d()\n",
    "    self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(2, 768), padding=True)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "    self.fc = nn.Linear(2132, 2) # before : 442 with max_length 36 # 806 with max_length 64 (1664,2)\n",
    "    self.flat = nn.Flatten()\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None): #\n",
    "    outputs = self.bert(input_ids, attention_mask=attention_mask, output_hidden_states=True, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds) #\n",
    "    all_layers = outputs[2]\n",
    "    x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n",
    "    del all_layers\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n",
    "    x = self.dropout(x)\n",
    "    x = self.flat(x)\n",
    "    x = self.dropout(x)\n",
    "    print(x.shape)\n",
    "    x = self.fc(x)\n",
    "    r = self.softmax(x)\n",
    "    logits=r\n",
    "    outputs = (logits,) + outputs[2:]\n",
    "    loss=0\n",
    "    loss_fct = CrossEntropyLoss(reduction='mean').cuda()\n",
    "    loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    outputs = (loss,) + outputs\n",
    "    return outputs\n",
    "\n",
    "# Class for weighted bert for sentence classification\n",
    "class SC_weighted_BERT(BertPreTrainedModel):\n",
    "    def __init__(self, config,weights):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.weights=weights\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=torch.tensor(self.weights).cuda())\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "# BERT for multitask learning\n",
    "class BertForMultitask(BertPreTrainedModel):\n",
    "    def __init__(self, config, label_uniques):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout_list=[]\n",
    "        self.classifier_list=[]\n",
    "        self.label_uniques=label_uniques\n",
    "        for ele in self.label_uniques:\n",
    "            self.dropout_list.append(nn.Dropout(config.hidden_dropout_prob))\n",
    "            self.classifier_list.append(nn.Linear(config.hidden_size, ele))\n",
    "        self.dropout_list=torch.nn.ModuleList(self.dropout_list)\n",
    "        self.classifier_list=torch.nn.ModuleList(self.classifier_list)\n",
    "\n",
    "        print(\"done\")\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        logits_list=[]\n",
    "        for i in range(len(self.label_uniques)):\n",
    "            output_1 = self.dropout_list[i](pooled_output)\n",
    "            logits = self.classifier_list[i](output_1)\n",
    "            logits_list.append(logits)\n",
    "        outputs = (logits_list,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        loss=0\n",
    "        for i in range(len(self.label_uniques)):\n",
    "            # label=torch.nn.functional.one_hot(labels[:,i])\n",
    "            label=labels[:,i]\n",
    "            loss_fct = CrossEntropyLoss(reduction='mean').cuda()\n",
    "            loss += loss_fct(logits_list[i].view(-1, self.label_uniques[i]), label.view(-1))\n",
    "        outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "def Eval_phase(params,which_files='test',model=None):\n",
    "\n",
    "  # For english, there is no translation, hence use full dataset.\n",
    "  if(params['language']=='English'):\n",
    "    params['csv_file']='*_full.csv'\n",
    "\n",
    "  # Load the files to test on\n",
    "\n",
    "  if(which_files=='train'):\n",
    "    path=params['files']+'/train/'+params['csv_file']\n",
    "    test_files=glob.glob(path)\n",
    "  if(which_files=='val'):\n",
    "    path=params['files']+'/val/'+params['csv_file']\n",
    "    test_files=glob.glob(path)\n",
    "  if(which_files=='test'):\n",
    "    path=params['files']+'/test/'+params['csv_file']\n",
    "    test_files=glob.glob(path)\n",
    "\n",
    "  '''Testing phase of the model'''\n",
    "  print('Loading BERT tokenizer...')\n",
    "  # Load bert tokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained(params['path_files'], do_lower_case=False)\n",
    "\n",
    "\t# If model is passed, then use the given model. Else load the model from the saved location\n",
    "\t# Put the model in evaluation mode--the dropout layers behave differently\n",
    "\t# during evaluation.\n",
    "  if(params['is_model']==True):\n",
    "    print(\"model previously passed\")\n",
    "    model.eval()\n",
    "  else:\n",
    "    model=select_model(params['what_bert'],params['path_files'],params['weights'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "\t# Load the dataset\n",
    "  print('-- Load dataset --')\n",
    "  print(test_files)\n",
    "  df_test=data_collector(test_files,params,False)\n",
    "  if(params['csv_file']=='*_translated.csv'):\n",
    "    sentences_test = df_test.translated.values\n",
    "  elif(params['csv_file']=='*_full.csv'):\n",
    "    sentences_test = df_test.text.values\n",
    "\n",
    "\n",
    "  labels_test = df_test.label.values\n",
    "\t# Encode the dataset using the tokenizer\n",
    "  input_test_ids,att_masks_test=combine_features(sentences_test,tokenizer,params['max_length'])\n",
    "  test_dataloader=return_dataloader(input_test_ids,labels_test,att_masks_test,batch_size=params['batch_size'],is_train=False)\n",
    "  print(\"Running eval on \",which_files,\"...\")\n",
    "  t0 = time.time()\n",
    "\n",
    "\t# Tracking variables\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  true_labels=[]\n",
    "  pred_labels=[]\n",
    "  for batch in test_dataloader:\n",
    "\t\t# Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\t\t# Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\t\t# Telling the model not to compute or store gradients, saving memory and\n",
    "\t\t# speeding up validation\n",
    "    with torch.no_grad():\n",
    "      outputs = model(b_input_ids,\n",
    "\t\t\t\t\t\t\ttoken_type_ids=None,\n",
    "\t\t\t\t\t\t\tattention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\t\t# Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    #print(logits.shape)\n",
    "    #print(label_ids.shape)\n",
    "    #label_ids=label_ids.reshape((16,))\n",
    "    #print(label_ids.shape)\n",
    "\t\t# Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "\t\t# Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    #pred_labels+=list(np.argmax(logits, axis=0).flatten())\n",
    "    pred_labels+=list(np.argmax(logits, axis=1).flatten())\n",
    "    true_labels+=list(label_ids.flatten())\n",
    "\n",
    "\t\t# Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  # Get the accuracy and macro f1 scores\n",
    "  testf1=f1_score(true_labels, pred_labels, average='macro')\n",
    "  testacc=accuracy_score(true_labels,pred_labels)\n",
    "  try:\n",
    "    testauc=roc_auc_score(true_labels,pred_labels, average='macro')\n",
    "  except ValueError:\n",
    "    testauc=0\n",
    "  testpred=precision_score(true_labels,pred_labels, average='macro')\n",
    "  testrec=recall_score(true_labels,pred_labels, average='macro')\n",
    "  cnf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "  plt.figure()\n",
    "  plot_confusion_matrix(cnf_matrix, classes=[\"Non_hate\", \"Hate\"],\n",
    "                        title='Confusion matrix, without normalization')\n",
    "  plt.show()\n",
    "\n",
    "\t# Log the metrics obtained\n",
    "\n",
    "  if(params['logging']!='neptune' or params['is_model'] == True):\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\" Accuracy: {0:.5f}\".format(testacc))\n",
    "    print(\" Fscore: {0:.5f}\".format(testf1))\n",
    "    print(\" AUC: {0:.5f}\".format(testauc))\n",
    "    print(\" Precision: {0:.5f}\".format(testpred))\n",
    "    print(\" Recall: {0:.5f}\".format(testrec))\n",
    "    print(\" Test took: {:}\".format(format_time(time.time() - t0)))\n",
    "  else: #neptune\n",
    "    bert_model = params['path_files'][:-1]\n",
    "    language  = params['language']\n",
    "    name_one=bert_model+\"_\"+language\n",
    "    neptune.create_experiment(name_one,params=params,send_hardware_metrics=False,run_monitoring_thread=False)\n",
    "    neptune.append_tag(bert_model)\n",
    "    neptune.append_tag(language)\n",
    "    neptune.append_tag('test')\n",
    "    neptune.log_metric('test_f1score',testf1)\n",
    "    neptune.log_metric('test_accuracy',testacc)\n",
    "    neptune.log_metric('test_auc',testauc)\n",
    "    neptune.log_metric('test_precision',testpred)\n",
    "    neptune.log_metric('test_recall',testrec)\n",
    "    neptune.stop()\n",
    "\n",
    "  return testf1,testacc,testauc,testpred,testrec\n",
    "\n",
    " # The main function that does the training\n",
    "def train_model(params,best_val_fscore):\n",
    "\n",
    "\t# In case of english languages, translation is the origin data itself.\n",
    "  if(params['language']=='English'):\n",
    "    params['csv_file']='*_full.csv'\n",
    "\n",
    "\n",
    "  train_path=params['files']+'/train/'+params['csv_file']\n",
    "  val_path=params['files']+'/val/'+params['csv_file']\n",
    "\n",
    "\t# Load the training and validation datasets\n",
    "  train_files=glob.glob(train_path)\n",
    "\n",
    "  print(train_files)\n",
    "  val_files=glob.glob(val_path)\n",
    "\n",
    "  print(val_files)\n",
    "\n",
    "\t#Load the bert tokenizer\n",
    "  print('Loading BERT tokenizer...')\n",
    "  tokenizer = BertTokenizer.from_pretrained(params['path_files'], do_lower_case=False)\n",
    "\n",
    "  df_train=data_collector(train_files,params,True)\n",
    "  df_val=data_collector(val_files,params,False)\n",
    "  print(len(df_train))\n",
    "\n",
    "\t# Get the comment texts and corresponding labels\n",
    "  if(params['csv_file']=='*_full.csv'):\n",
    "    sentences_train = df_train.text.values\n",
    "    sentences_val = df_val.text.values\n",
    "  elif(params['csv_file']=='*_translated.csv'):\n",
    "    sentences_train = df_train.translated.values\n",
    "    sentences_val = df_val.translated.values\n",
    "\n",
    "  labels_train = df_train.label.values\n",
    "  labels_val = df_val.label.values\n",
    "  label_counts=df_train['label'].value_counts()\n",
    "  print(label_counts)\n",
    "\n",
    "  label_weights = [ (len(df_train))/label_counts[0],len(df_train)/label_counts[1] ]\n",
    "  print(label_weights)\n",
    "\n",
    "\n",
    "\t# Select the required bert model. Refer below for explanation of the parameter values.\n",
    "  model=select_model(params['what_bert'],params['path_files'],params['weights'])\n",
    "\t# Tell pytorch to run this model on the GPU.\n",
    "  model.cuda()\n",
    "\n",
    "\t# Do the required encoding using the bert tokenizer\n",
    "  input_train_ids,att_masks_train=combine_features(sentences_train,tokenizer,params['max_length'])\n",
    "  #input_val_ids,att_masks_val=combine_features(sentences_val,tokenizer,params['max_length'])\n",
    "\n",
    "\t# Create dataloaders for both the train and validation datasets.\n",
    "  train_dataloader = return_dataloader(input_train_ids,labels_train,att_masks_train,batch_size=params['batch_size'],is_train=params['is_train'])\n",
    "  #validation_dataloader=return_dataloader(input_val_ids,labels_val,att_masks_val,batch_size=params['batch_size'],is_train=False)\n",
    "\n",
    "\t# Initialize AdamW optimizer.\n",
    "  optimizer = AdamW(model.parameters(),\n",
    "\t\t\t\t  lr = params['learning_rate'], # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "\t\t\t\t  eps = params['epsilon'] # args.adam_epsilon  - default is 1e-8.\n",
    "\t\t\t\t)\n",
    "\n",
    "\t# Number of training epochs (authors recommend between 2 and 4)\n",
    "\t# Total number of training steps is number of batches * number of epochs.\n",
    "  total_steps = len(train_dataloader) * params['epochs']\n",
    "\n",
    "\t# Create the learning rate scheduler.\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_warmup_steps = int(total_steps/10), # Default value in run_glue.py\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_training_steps = total_steps)\n",
    "\n",
    "\t# Set the seed value all over the place to make this reproducible.\n",
    "  fix_the_random(seed_val = params['random_seed'])\n",
    "\t# Store the average loss after each epoch so we can plot them.\n",
    "  loss_values = []\n",
    "\n",
    "\t# Create a new experiment in neptune for this run.\n",
    "  bert_model = params['path_files']\n",
    "  language  = params['language']\n",
    "  name_one=bert_model+\"_\"+language\n",
    "  if(params['logging']=='neptune'):\n",
    "    neptune.create_experiment(name_one,params=params,send_hardware_metrics=False,run_monitoring_thread=False)\n",
    "    neptune.append_tag(bert_model)\n",
    "    neptune.append_tag(language)\n",
    "\n",
    "\t# The best val fscore obtained till now, for the purpose of hyper parameter finetuning.\n",
    "  best_val_fscore=best_val_fscore\n",
    "\n",
    "\t# For each epoch...\n",
    "  for epoch_i in range(0, params['epochs']):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, params['epochs']))\n",
    "    print('Training...')\n",
    "\n",
    "\t\t# Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "\t\t# Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "\t\t# For each batch of training data...\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "\t\t\t# Progress update every 40 batches.\n",
    "      if step % 40 == 0 and not step == 0:\n",
    "\t\t\t\t# Calculate elapsed time in minutes.\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "\t\t\t# `batch` contains three pytorch tensors:\n",
    "\t\t\t#   [0]: input ids\n",
    "\t\t\t#   [1]: attention masks\n",
    "\t\t\t#   [2]: labels\n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_input_mask = batch[1].to(device)\n",
    "      b_labels = batch[2].to(device)\n",
    "\t\t\t# (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "      model.zero_grad()\n",
    "      #print(b_labels)\n",
    "\t\t\t# Get the model outputs for this batch.\n",
    "      outputs = model(b_input_ids,\n",
    "\t\t\t\t\t\ttoken_type_ids=None,\n",
    "\t\t\t\t\t\tattention_mask=b_input_mask,\n",
    "\t\t\t\t\t\tlabels=b_labels)\n",
    "\n",
    "\t\t\t# The call to `model` always returns a tuple, so we need to pull the\n",
    "\t\t\t# loss value out of the tuple.\n",
    "      loss = outputs[0]\n",
    "      #cross_entropy = nn.NLLLoss()\n",
    "      #loss = cross_entropy(outputs, b_labels)\n",
    "\t\t\t#if(params['logging']=='neptune'):\n",
    "\t\t\t#\tneptune.log_metric('batch_loss',loss)\n",
    "\t\t\t# Accumulate the training loss over all of the batches so that we can\n",
    "\t\t\t# calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "\t\t\t# single value; the `.item()` function just returns the Python value\n",
    "\t\t\t# from the tensor.\n",
    "      total_loss += loss.item()\n",
    "\n",
    "\t\t\t# Perform a backward pass to calculate the gradients.\n",
    "      loss.backward()\n",
    "\n",
    "\t\t\t# Clip the norm of the gradients to 1.0.\n",
    "\t\t\t# This is to help prevent the \"exploding gradients\" problem.\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\t\t\t# Update parameters and take a step using the computed gradient.\n",
    "\t\t\t# The optimizer dictates the \"update rule\"--how the parameters are\n",
    "\t\t\t# modified based on their gradients, the learning rate, etc.\n",
    "      optimizer.step()\n",
    "\t\t\t# Update the learning rate.\n",
    "      scheduler.step()\n",
    "\t\t# Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    if(params['logging']=='neptune'):\n",
    "      neptune.log_metric('avg_train_loss',avg_train_loss)\n",
    "\n",
    "\n",
    "\t\t# Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\t\t# Compute the metrics on the validation and test sets.\n",
    "    val_fscore,val_accuracy,val_auc,val_pred,val_rec=Eval_phase(params,'val',model)\n",
    "    test_fscore,test_accuracy,test_auc,test_pred,test_rec=Eval_phase(params,'test',model)\n",
    "\n",
    "\t\t#Report the final accuracy and fscore for this validation run.\n",
    "    if(params['logging']=='neptune'):\n",
    "      neptune.log_metric('val_fscore',val_fscore)\n",
    "      neptune.log_metric('val_acc',val_accuracy)\n",
    "      neptune.log_metric('val_auc',val_auc)\n",
    "      neptune.log_metric('val_pred',val_pred)\n",
    "      neptune.log_metric('val_rec',val_rec)\n",
    "      neptune.log_metric('test_fscore',test_fscore)\n",
    "      neptune.log_metric('test_accuracy',test_accuracy)\n",
    "      neptune.log_metric('test_auc',test_auc)\n",
    "      neptune.log_metric('test_pred',test_pred)\n",
    "      neptune.log_metric('test_rec',test_rec)\n",
    "\n",
    "\t\t# Save the model only if the validation fscore improves. After all epochs, the best model is the final saved one.\n",
    "    if(val_fscore > best_val_fscore):\n",
    "      print(val_fscore,best_val_fscore)\n",
    "    #if(test_fscore > best_val_fscore):\n",
    "      #print(test_fscore,best_val_fscore)\n",
    "      best_val_fscore=val_fscore\n",
    "      save_model(model,tokenizer,params)\n",
    "\n",
    "  if(params['logging']=='neptune'):\n",
    "    neptune.stop()\n",
    "  del model\n",
    "  torch.cuda.empty_cache()\n",
    "  return val_fscore,best_val_fscore\n",
    "\n",
    "\n",
    "\n",
    "def create_divs(filename):\n",
    "    df = pd.read_csv('Dataset/full_data/'+filename)\n",
    "    if not os.path.exists('Dataset/train'):\n",
    "        os.makedirs('Dataset/train')\n",
    "    if not os.path.exists('Dataset/val'):\n",
    "        os.makedirs('Dataset/val')\n",
    "    if not os.path.exists('Dataset/test'):\n",
    "        os.makedirs('Dataset/test')\n",
    "    train_df_ids = list(pd.read_csv('Dataset/ID Mapping/train/'+filename)['id'])\n",
    "    train_df = df.iloc[train_df_ids]\n",
    "    train_df.to_csv('Dataset/train/'+filename,index=False)\n",
    "    val_df_ids = list(pd.read_csv('Dataset/ID Mapping/val/'+filename)['id'])\n",
    "    val_df = df.iloc[val_df_ids]\n",
    "    val_df.to_csv('Dataset/val/'+filename,index=False)\n",
    "    test_df_ids = list(pd.read_csv('Dataset/ID Mapping/test/'+filename)['id'])\n",
    "    test_df = df.iloc[test_df_ids]\n",
    "    test_df.to_csv('Dataset/test/'+filename,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_QkBz6UCQva"
   },
   "source": [
    "# Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed__7z4tQWDo"
   },
   "outputs": [],
   "source": [
    "## Creacion de ID Mapping\n",
    "import random\n",
    "\n",
    "cols = ['tweet','class']\n",
    "load_path = 'Dataset/full_data/English_2a_full.csv'\n",
    "filename='English_2a_full.csv'\n",
    "\n",
    "df = pd.read_csv(load_path, usecols=cols)\n",
    "df.index.name = 'id'\n",
    "#df = df.rename(columns={\"tweet\": \"text\", \"class\":'label'})\n",
    "#df[\"label\"].replace({0: 1, 1: 0, 2: 0}, inplace=True) #davidson\n",
    "df.to_csv('Dataset/full_data/'+filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rZinjFJ8Uhs"
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('Dataset/full_data/Spanish_8b_full.csv')\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mkDeea0pc_R"
   },
   "outputs": [],
   "source": [
    "train_data = full_data.id[:2712]\n",
    "test_data = full_data.id[2713:3052]\n",
    "val_data = full_data.id[3053:]\n",
    "\n",
    "filename = \"Spanish_8b_full.csv\"\n",
    "df = pd.DataFrame({'id': train_data})\n",
    "df.to_csv(\"Dataset/ID Mapping/train/\"+filename,index=False)\n",
    "df = pd.DataFrame({'id': test_data})\n",
    "df.to_csv(\"Dataset/ID Mapping/test/\"+filename,index=False)\n",
    "df = pd.DataFrame({'id': val_data})\n",
    "df.to_csv(\"Dataset/ID Mapping/val/\"+filename,index=False)\n",
    "\n",
    "create_divs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xga6N9dCUbct"
   },
   "outputs": [],
   "source": [
    "### Run\n",
    "params={\n",
    "    #'logging':'neptune',\n",
    "    'logging':'local',\n",
    "    'language':'Spanish',\n",
    "    'is_train':True,\n",
    "    'is_model':True,\n",
    "    'learning_rate':2e-5,\n",
    "    'files':'Dataset',\n",
    "    'csv_file':'*_full.csv',\n",
    "    'samp_strategy':'stratified',\n",
    "    'epsilon':1e-6,\n",
    "    #'path_files':'bert-base-cased',\n",
    "    #'path_files':'bert-base-multilingual-cased',\n",
    "    'path_files':'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    #'path_files':'models_saved/smith_wsp_pretrain_ckpt_opensource/',\n",
    "    'take_ratio':False,\n",
    "    #'take_ratio':True,\n",
    "    'sample_ratio':100,\n",
    "    'how_train':'baseline',\n",
    "    'epochs':5,\n",
    "    'batch_size':32,\n",
    "    'to_save':True,\n",
    "    'weights':[1.0,1.0],\n",
    "    'what_bert':'normal',\n",
    "    #'what_bert':'bert_cnn', # A BERT-based ...\n",
    "    'save_only_bert':False,\n",
    "    'max_length':256,\n",
    "    'random_seed':2018\n",
    "}\n",
    "\n",
    "\n",
    "neptune.init(project_name,api_token=api_token)\n",
    "neptune.set_project(project_name)\n",
    "filename = \"Spanish_8b_full.csv\"\n",
    "\n",
    "\n",
    "lang = 'Spanish'\n",
    "best_val_fscore=00\n",
    "\n",
    "for bs in [16,32]:\n",
    "  params['batch_size']=bs\n",
    "  for lr in [2e-5,3e-5,5e-5]:\n",
    "    params['learning_rate']=lr\n",
    "    params['samp_strategy']='stratified'\n",
    "    for seed in [2018,2019,2020,2021,2022,2023]:\n",
    "        params['random_seed']=seed\n",
    "        _,best_val_fscore=train_model(params,best_val_fscore)\n",
    "\n",
    "print('============================')\n",
    "print('Model for Language',lang,'is trained')\n",
    "print('============================')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HaterBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
